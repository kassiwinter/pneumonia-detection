{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dd57ba-2bf7-4d6e-9339-438d5d7ae997",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d563c-0c77-4510-9d2f-3bb3b44da5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9452d2f-d9e6-4c90-88e5-16843888e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = \"/content/drive/MyDrive/MLProjects/dataset/chest_xray\"\n",
    "data_dir_train = \"/content/drive/MyDrive/MLProjects/dataset/chest_xray/Train\"\n",
    "data_dir_validation = \"/content/drive/MyDrive/MLProjects/dataset/chest_xray/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80098379-60ee-4ea6-aa60-ab3ab405b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import imghdr\n",
    "\n",
    "data_dir = \"/content/drive/MyDrive/MLProjects/dataset/chest_xray/\"\n",
    "image_extensions = [\".png\", \".svg\", \".gif\", \".jpg\"]  # add there all your images file extensions\n",
    "\n",
    "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "for filepath in Path(data_dir).rglob(\"*\"):\n",
    "    if filepath.suffix.lower() in image_extensions:\n",
    "        img_type = imghdr.what(filepath)\n",
    "        if img_type is None:\n",
    "            print(f\"{filepath} is not an image\")\n",
    "        elif img_type not in img_type_accepted_by_tf:\n",
    "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c731461-48c0-40e6-ac60-0a6fb85175bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height,img_width=180, 180\n",
    "batch_size=32\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30881563-f009-46fc-978f-975f90d78516",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_validation,\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e89e59-602a-4a8b-a7cf-b6d3fe65b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1acaa6-2db9-4777-8af3-934266badfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41a3bf-4f6f-4749-966a-2e3d500e8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105d7e0-c0f8-4443-a049-891d22c25cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c4b5fe-eee2-4834-9179-8809943d5662",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=3\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11a20c-d029-46ac-9ae9-dad68b0610f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation=2\n",
    "model = model((180,180,3),activation)\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9da0a-0099-4d14-9132-87c8c261fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model,'xray_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4e7515-bcb1-4b2d-a3f0-7622ca5808b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7504f68-e8a9-4577-a187-3e104599be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "import streamlit as st\n",
    "\n",
    "\n",
    "@st.cache(allow_output_mutation=True)\n",
    "def load_model():\n",
    "  model=tf.keras.models.load_model('/content/my_model2.hdf5')\n",
    "  return model\n",
    "with st.spinner('Model is being loaded..'):\n",
    "  model=load_model()\n",
    "\n",
    "st.write(\"\"\"\n",
    "         # Flower Classification\n",
    "         \"\"\"\n",
    "         )\n",
    "\n",
    "file = st.file_uploader(\"Please upload an brain scan file\", type=[\"jpg\", \"png\"])\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
    "def import_and_predict(image_data, model):\n",
    "    \n",
    "        size = (180,180)    \n",
    "        image = ImageOps.fit(image_data, size, Image.ANTIALIAS)\n",
    "        image = np.asarray(image)\n",
    "        img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #img_resize = (cv2.resize(img, dsize=(75, 75),    interpolation=cv2.INTER_CUBIC))/255.\n",
    "        \n",
    "        img_reshape = img[np.newaxis,...]\n",
    "    \n",
    "        prediction = model.predict(img_reshape)\n",
    "        \n",
    "        return prediction\n",
    "if file is None:\n",
    "    st.text(\"Please upload an image file\")\n",
    "else:\n",
    "    image = Image.open(file)\n",
    "    st.image(image, use_column_width=True)\n",
    "    predictions = import_and_predict(image, model)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    st.write(prediction)\n",
    "    st.write(score)\n",
    "    print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
